{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-1，张量的结构操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量的操作主要包括张量的结构操作和张量的数学运算。\n",
    "\n",
    "张量结构操作诸如：张量创建，索引切片，维度变换，合并分割。\n",
    "\n",
    "张量数学运算主要有：标量运算，向量运算，矩阵运算。另外我们会介绍张量运算的广播机制。\n",
    "\n",
    "本篇我们介绍张量的结构操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、创建张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量创建的许多方法和numpy中创建array的方法很像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1,2,3],dtype=tf.float32)\n",
    "print(a)\n",
    "tf.print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 8 6 4 2]\n"
     ]
    }
   ],
   "source": [
    "b = tf.range(10,1,delta=-2)\n",
    "tf.print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 8 6 4 2 0]\n"
     ]
    }
   ],
   "source": [
    "c = tf.linspace(10,0,6)\n",
    "tf.print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "d = tf.zeros([3,3])\n",
    "tf.print(d)\n",
    "tf.print(d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1]\n",
      " [1 1 1]\n",
      " [1 1 1]]\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones([3,3])\n",
    "b = tf.zeros_like(a,dtype=tf.float32)\n",
    "tf.print(a)\n",
    "tf.print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 5]\n",
      " [5 5]\n",
      " [5 5]]\n"
     ]
    }
   ],
   "source": [
    "b = tf.fill([3,2],5)\n",
    "tf.print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.32600474 6.45835161 6.99905777 2.62959361 5.51486492]\n",
      " [6.71703339 0.214263201 1.72008634 0.739969 7.9267621]\n",
      " [8.48169422 7.78671646 6.29696751 8.3506546 2.947855]\n",
      " [4.23601627 6.81895733 1.99285746 8.06989861 8.87176418]\n",
      " [8.76599121 1.81831121 5.02958059 0.234712362 1.4948988]]\n",
      "(5, 5)\n"
     ]
    }
   ],
   "source": [
    "# 均匀分布随机\n",
    "# tf.random.set_seed(1) # 设置随机种子\n",
    "a = tf.random.uniform([5,5],minval=0,maxval=10)\n",
    "tf.print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.87371 0.274597406 -0.0364042595 -0.506392241 -0.201665327]\n",
      " [-0.777061701 1.72137773 -0.121972382 0.741182566 1.04614925]\n",
      " [-0.0727615356 1.26759028 0.957027435 1.30794752 1.70221901]\n",
      " [0.559168518 -0.483352512 0.168694586 0.32278493 0.332817]\n",
      " [0.0186989419 -0.448576629 0.667761385 -1.54900885 1.26717639]]\n"
     ]
    }
   ],
   "source": [
    "# 正太随机分布\n",
    "b = tf.random.normal(a.shape,mean=0,stddev=1)\n",
    "tf.print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.834074318 -1.02077544 -0.63425678 0.515412748 0.865244269]\n",
      " [1.16046584 -1.42690039 -0.833565116 -1.58683121 -0.215022638]\n",
      " [-0.955602407 -0.054117579 0.683828652 -0.467878103 0.208319575]\n",
      " [-0.0726841092 0.866283357 -0.350806683 -1.69972456 1.74361813]\n",
      " [0.630323589 0.23178412 0.450689584 -0.312031507 1.43233383]]\n"
     ]
    }
   ],
   "source": [
    "#正态分布随机，剔除2倍方差以外数据重新生成\n",
    "c = tf.random.truncated_normal(a.shape,mean=0,stddev=1)\n",
    "tf.print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]]\n",
      "[[1 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "# 特殊矩阵\n",
    "I = tf.eye(4,4)\n",
    "tf.print(I)\n",
    "\n",
    "N = tf.linalg.diag([1,2,3,4])\n",
    "tf.print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、索引切片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "张量的索引切片方式和numpy几乎是一样的。切片时支持缺省参数和省略号。\n",
    "\n",
    "对于tf.Variable,可以通过索引和切片对部分元素进行修改。\n",
    "\n",
    "对于提取张量的连续子区域，也可以使用tf.slice.\n",
    "\n",
    "此外，对于不规则的切片提取,可以使用tf.gather,tf.gather_nd,tf.boolean_mask。\n",
    "\n",
    "tf.boolean_mask功能最为强大，它可以实现tf.gather,tf.gather_nd的功能，并且tf.boolean_mask还可以实现布尔索引。\n",
    "\n",
    "如果要通过修改张量的某些元素得到新的张量，可以使用tf.where，tf.scatter_nd。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 7 4 2 9]\n",
      " [9 1 2 4 7]\n",
      " [7 2 7 4 0]\n",
      " [9 6 9 7 2]\n",
      " [3 7 0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(3)\n",
    "t = tf.random.uniform([5,5],minval=0,maxval=10,dtype=tf.int32)\n",
    "tf.print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 7 4 2 9]\n",
      "[3 7 0 0 3]\n",
      "[4 9 7 9 3]\n",
      "[9 7 0 2 3]\n"
     ]
    }
   ],
   "source": [
    "tf.print(t[0])\n",
    "tf.print(t[-1])\n",
    "tf.print(t[:,0])\n",
    "tf.print(t[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 1 2 4 7]\n",
      " [7 2 7 4 0]\n",
      " [9 6 9 7 2]]\n",
      "[[9 1 2 4 7]\n",
      " [7 2 7 4 0]\n",
      " [9 6 9 7 2]]\n"
     ]
    }
   ],
   "source": [
    "tf.print(t[1:4,:])\n",
    "tf.print(tf.slice(t,[1,0],[3,5])) # 切片，data，start，end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9 2]\n",
      " [7 7]\n",
      " [9 9]]\n",
      "[[9 2]\n",
      " [9 9]]\n"
     ]
    }
   ],
   "source": [
    "#第1行至最后一行，第0列到最后一列每隔两列取一列\n",
    "tf.print(t[1:4,:4:2])\n",
    "tf.print(t[1:4:2,:4:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1 2]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "#对变量来说，还可以使用索引和切片修改部分元素\n",
    "x = tf.Variable([[1,2],[3,4]])\n",
    "tf.print(x)\n",
    "x[1,:].assign(tf.constant([0,0]))\n",
    "tf.print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[7 3]\n",
      "  [9 9]]\n",
      "\n",
      " [[0 7]\n",
      "  [9 6]]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform([2,2,2],minval=0,maxval=10,dtype=tf.int32)\n",
    "tf.print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 9]\n",
      " [7 6]]\n",
      "[[3 9]\n",
      " [7 6]]\n"
     ]
    }
   ],
   "source": [
    "#省略号可以表示多个冒号\n",
    "tf.print(a[...,1])\n",
    "tf.print(a[:,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上切片方式相对规则，对于不规则的切片提取,可以使用tf.gather,tf.gather_nd,tf.boolean_mask。\n",
    "\n",
    "考虑班级成绩册的例子，有4个班级，每个班级10个学生，每个学生7门科目成绩。可以用一个4×10×7的张量来表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[52 82 66 ... 17 86 14]\n",
      "  [8 36 94 ... 13 78 41]\n",
      "  [77 53 51 ... 22 91 56]\n",
      "  ...\n",
      "  [11 19 26 ... 89 86 68]\n",
      "  [60 72 0 ... 11 26 15]\n",
      "  [24 99 38 ... 97 44 74]]\n",
      "\n",
      " [[79 73 73 ... 35 3 81]\n",
      "  [83 36 31 ... 75 38 85]\n",
      "  [54 26 67 ... 60 68 98]\n",
      "  ...\n",
      "  [20 5 18 ... 32 45 3]\n",
      "  [72 52 81 ... 88 41 20]\n",
      "  [0 21 89 ... 53 10 90]]\n",
      "\n",
      " [[52 80 22 ... 29 25 60]\n",
      "  [78 71 54 ... 43 98 81]\n",
      "  [21 66 53 ... 97 75 77]\n",
      "  ...\n",
      "  [6 74 3 ... 53 65 43]\n",
      "  [98 36 72 ... 33 36 81]\n",
      "  [61 78 70 ... 7 59 21]]\n",
      "\n",
      " [[56 57 45 ... 23 15 3]\n",
      "  [35 8 82 ... 11 59 97]\n",
      "  [44 6 99 ... 81 60 27]\n",
      "  ...\n",
      "  [76 26 35 ... 51 8 17]\n",
      "  [33 52 53 ... 78 37 31]\n",
      "  [71 27 44 ... 0 52 16]]]\n"
     ]
    }
   ],
   "source": [
    "scores = tf.random.uniform((4,10,7),minval=0,maxval=100,dtype=tf.int32)\n",
    "tf.print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[52 82 66 ... 17 86 14]\n",
      "  [24 80 70 ... 72 63 96]\n",
      "  [24 99 38 ... 97 44 74]]\n",
      "\n",
      " [[79 73 73 ... 35 3 81]\n",
      "  [46 10 94 ... 23 18 92]\n",
      "  [0 21 89 ... 53 10 90]]\n",
      "\n",
      " [[52 80 22 ... 29 25 60]\n",
      "  [19 12 23 ... 87 86 25]\n",
      "  [61 78 70 ... 7 59 21]]\n",
      "\n",
      " [[56 57 45 ... 23 15 3]\n",
      "  [6 41 79 ... 97 43 13]\n",
      "  [71 27 44 ... 0 52 16]]]\n"
     ]
    }
   ],
   "source": [
    "#抽取每个班级第0个学生，第5个学生，第9个学生的全部成绩\n",
    "p = tf.gather(scores,[0,5,9],axis=1)\n",
    "tf.print(p) # (4,3,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[82 55 14]\n",
      "  [80 46 96]\n",
      "  [99 58 74]]\n",
      "\n",
      " [[73 48 81]\n",
      "  [10 38 92]\n",
      "  [21 86 90]]\n",
      "\n",
      " [[80 57 60]\n",
      "  [12 34 25]\n",
      "  [78 71 21]]\n",
      "\n",
      " [[57 75 3]\n",
      "  [41 47 13]\n",
      "  [27 96 16]]]\n"
     ]
    }
   ],
   "source": [
    "#抽取每个班级第0个学生，第5个学生，第9个学生的第1门课程，第3门课程，第6门课程成绩\n",
    "q = tf.gather(tf.gather(scores,[0,5,9],axis=1),[1,3,6],axis=2)\n",
    "tf.print(q) #(4,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52 82 66 ... 17 86 14]\n",
      " [99 94 46 ... 1 63 41]\n",
      " [46 83 70 ... 90 85 17]]\n"
     ]
    }
   ],
   "source": [
    "# 抽取第0个班级第0个学生，第2个班级的第4个学生，第3个班级的第6个学生的全部成绩\n",
    "#indices的长度为采样样本的个数，每个元素为采样位置的坐标\n",
    "s = tf.gather_nd(scores,indices = [(0,0),(2,4),(3,6)])\n",
    "tf.print(s) # (3,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上tf.gather和tf.gather_nd的功能也可以用tf.boolean_mask来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[52 82 66 ... 17 86 14]\n",
      "  [24 80 70 ... 72 63 96]\n",
      "  [24 99 38 ... 97 44 74]]\n",
      "\n",
      " [[79 73 73 ... 35 3 81]\n",
      "  [46 10 94 ... 23 18 92]\n",
      "  [0 21 89 ... 53 10 90]]\n",
      "\n",
      " [[52 80 22 ... 29 25 60]\n",
      "  [19 12 23 ... 87 86 25]\n",
      "  [61 78 70 ... 7 59 21]]\n",
      "\n",
      " [[56 57 45 ... 23 15 3]\n",
      "  [6 41 79 ... 97 43 13]\n",
      "  [71 27 44 ... 0 52 16]]]\n"
     ]
    }
   ],
   "source": [
    "#抽取每个班级第0个学生，第5个学生，第9个学生的全部成绩\n",
    "p = tf.boolean_mask(scores,[True,False,False,False,False,\n",
    "                            True,False,False,False,True],axis=1)\n",
    "tf.print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52 82 66 ... 17 86 14]\n",
      " [99 94 46 ... 1 63 41]\n",
      " [46 83 70 ... 90 85 17]]\n"
     ]
    }
   ],
   "source": [
    "#抽取第0个班级第0个学生，第2个班级的第4个学生，第3个班级的第6个学生的全部成绩\n",
    "s = tf.boolean_mask(scores,\n",
    "    [[True,False,False,False,False,False,False,False,False,False],\n",
    "     [False,False,False,False,False,False,False,False,False,False],\n",
    "     [False,False,False,False,True,False,False,False,False,False],\n",
    "     [False,False,False,False,False,False,True,False,False,False]])\n",
    "tf.print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 1 -1]\n",
      " [2 2 -2]\n",
      " [3 -3 3]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#利用tf.boolean_mask可以实现布尔索引\n",
    "\n",
    "#找到矩阵中小于0的元素\n",
    "c = tf.constant([[-1,1,-1],[2,2,-2],[3,-3,3]],dtype=tf.float32)\n",
    "tf.print(c,\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=bool, numpy=\n",
       "array([[ True, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False]])>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c<0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -2 -3]\n",
      "[-1 -1 -2 -3]\n"
     ]
    }
   ],
   "source": [
    "tf.print(tf.boolean_mask(c,c<0))\n",
    "tf.print(c[c<0]) #布尔索引，为boolean_mask的语法糖形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上这些方法仅能提取张量的部分元素值，但不能更改张量的部分元素值得到新的张量。\n",
    "\n",
    "如果要通过修改张量的部分元素值得到新的张量，可以使用tf.where和tf.scatter_nd。\n",
    "\n",
    "tf.where可以理解为if的张量版本，此外它还可以用于找到满足条件的所有元素的位置坐标。\n",
    "\n",
    "tf.scatter_nd的作用和tf.gather_nd有些相反，tf.gather_nd用于收集张量的给定位置的元素，\n",
    "\n",
    "而tf.scatter_nd可以将某些值插入到一个给定shape的全0的张量的指定位置处"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1 1 -1]\n",
      " [2 2 -2]\n",
      " [3 -3 3]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan]], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#找到张量中小于0的元素,将其换成np.nan得到新的张量\n",
    "#tf.where和np.where作用类似，可以理解为if的张量版本\n",
    "c = tf.constant([[-1,1,-1],[2,2,-2],[3,-3,3]],dtype=tf.float32)\n",
    "tf.print(c)\n",
    "tf.fill(c.shape,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan 1 nan]\n",
      " [2 2 nan]\n",
      " [3 nan 3]]\n"
     ]
    }
   ],
   "source": [
    "d = tf.where(c<0,tf.fill(c.shape,np.nan),c)# 参数(condition, x=None, y=None, name=None)\n",
    "tf.print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=int64, numpy=\n",
       "array([[0, 0],\n",
       "       [0, 2],\n",
       "       [1, 2],\n",
       "       [2, 1]])>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#如果where只有一个参数，将返回所有满足条件的位置坐标\n",
    "indices = tf.where(c<0) \n",
    "indices # 有4个数据是小于0 的，每个数的位置是个列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter_nd的使用方法\n",
    "indices = tf.constant([[4], [3], [1], [7]]) # 下标\n",
    "updates = tf.constant([9, 10, 11, 12])\n",
    "shape = tf.constant([8])\n",
    "scatter = tf.scatter_nd(indices, updates, shape)\n",
    "print(scatter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[ 0.,  1., -1.],\n",
       "       [ 2.,  2., -2.],\n",
       "       [ 3.,  0.,  3.]], dtype=float32)>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将张量的第[0,0]和[2,1]两个位置元素替换为0得到新的张量\n",
    "d = c - tf.scatter_nd([[0,0],[2,1]],[c[0,0],c[2,1]],c.shape)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[-1.,  0., -1.],\n",
       "       [ 0.,  0., -2.],\n",
       "       [ 0., -3.,  0.]], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scatter_nd的作用和gather_nd有些相反\n",
    "#可以将某些值插入到一个给定shape的全0的张量的指定位置处。\n",
    "indices = tf.where(c<0)\n",
    "tf.scatter_nd(indices,tf.gather_nd(c,indices),c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、维度变换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维度变换相关函数主要有 tf.reshape, tf.squeeze, tf.expand_dims, tf.transpose.\n",
    "\n",
    "tf.reshape 可以改变张量的形状。\n",
    "\n",
    "tf.squeeze 可以减少维度。\n",
    "\n",
    "tf.expand_dims 可以增加维度。\n",
    "\n",
    "tf.transpose 可以交换维度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.reshape可以改变张量的形状，但是其本质上不会改变张量元素的存储顺序，所以，该操作实际上非常迅速，并且是可逆的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([1, 3, 3, 2])\n",
      "[[[[100 44]\n",
      "   [181 14]\n",
      "   [90 53]]\n",
      "\n",
      "  [[205 141]\n",
      "   [14 24]\n",
      "   [239 46]]\n",
      "\n",
      "  [[225 174]\n",
      "   [212 78]\n",
      "   [14 144]]]]\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.uniform(shape=[1,3,3,2],\n",
    "                      minval=0,maxval=255,dtype=tf.int32)\n",
    "tf.print(a.shape)\n",
    "tf.print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([3, 6])\n",
      "[[100 44 181 14 90 53]\n",
      " [205 141 14 24 239 46]\n",
      " [225 174 212 78 14 144]]\n"
     ]
    }
   ],
   "source": [
    "# 改成 （3,6）形状的张量\n",
    "b = tf.reshape(a,[3,6])\n",
    "tf.print(b.shape)\n",
    "tf.print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[100 44]\n",
      "   [181 14]\n",
      "   [90 53]]\n",
      "\n",
      "  [[205 141]\n",
      "   [14 24]\n",
      "   [239 46]]\n",
      "\n",
      "  [[225 174]\n",
      "   [212 78]\n",
      "   [14 144]]]]\n"
     ]
    }
   ],
   "source": [
    "# 改回成 [1,3,3,2] 形状的张量\n",
    "c = tf.reshape(b,[1,3,3,2])\n",
    "tf.print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果张量在某个维度上只有一个元素，利用tf.squeeze可以消除这个维度。\n",
    "\n",
    "和tf.reshape相似，它本质上不会改变张量元素的存储顺序。\n",
    "\n",
    "张量的各个元素在内存中是线性存储的，其一般规律是，同一层级中的相邻元素的物理地址也相邻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([3, 3, 2])\n",
      "[[[100 44]\n",
      "  [181 14]\n",
      "  [90 53]]\n",
      "\n",
      " [[205 141]\n",
      "  [14 24]\n",
      "  [239 46]]\n",
      "\n",
      " [[225 174]\n",
      "  [212 78]\n",
      "  [14 144]]]\n"
     ]
    }
   ],
   "source": [
    "s = tf.squeeze(a)\n",
    "tf.print(s.shape)\n",
    "tf.print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3, 2), dtype=int32, numpy=\n",
       "array([[[[100,  44],\n",
       "         [181,  14],\n",
       "         [ 90,  53]],\n",
       "\n",
       "        [[205, 141],\n",
       "         [ 14,  24],\n",
       "         [239,  46]],\n",
       "\n",
       "        [[225, 174],\n",
       "         [212,  78],\n",
       "         [ 14, 144]]]], dtype=int32)>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = tf.expand_dims(s,axis=0) #在第0维插入长度为1的一个维度\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3, 3, 2), dtype=int32, numpy=\n",
       "array([[[[100,  44],\n",
       "         [181,  14],\n",
       "         [ 90,  53]],\n",
       "\n",
       "        [[205, 141],\n",
       "         [ 14,  24],\n",
       "         [239,  46]],\n",
       "\n",
       "        [[225, 174],\n",
       "         [212,  78],\n",
       "         [ 14, 144]]]], dtype=int32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = tf.expand_dims(s,axis=0) #在第0维插入长度为1的一个维度\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.transpose可以交换张量的维度，与tf.reshape不同，它会改变张量元素的存储顺序。\n",
    "\n",
    "tf.transpose常用于图片存储格式的变换上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorShape([100, 600, 600, 4])\n",
      "TensorShape([4, 600, 600, 100])\n"
     ]
    }
   ],
   "source": [
    "# Batch,Height,Width,Channel\n",
    "a = tf.random.uniform(shape=[100,600,600,4],minval=0,maxval=255,dtype=tf.int32)\n",
    "tf.print(a.shape)\n",
    "\n",
    "# 转换成 Channel,Height,Width,Batch\n",
    "s= tf.transpose(a,perm=[3,1,2,0])\n",
    "tf.print(s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、合并分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和numpy类似，可以用tf.concat和tf.stack方法对多个张量进行合并，可以用tf.split方法把一个张量分割成多个张量。\n",
    "\n",
    "tf.concat和tf.stack有略微的区别，tf.concat是连接，不会增加维度，而tf.stack是堆叠，会增加维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 2), dtype=float32, numpy=\n",
       "array([[ 1.,  2.],\n",
       "       [ 3.,  4.],\n",
       "       [ 5.,  6.],\n",
       "       [ 7.,  8.],\n",
       "       [ 9., 10.],\n",
       "       [11., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1.0,2.0],[3.0,4.0]])\n",
    "b = tf.constant([[5.0,6.0],[7.0,8.0]])\n",
    "c = tf.constant([[9.0,10.0],[11.0,12.0]])\n",
    "\n",
    "tf.concat([a,b,c],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=float32, numpy=\n",
       "array([[ 1.,  2.,  5.,  6.,  9., 10.],\n",
       "       [ 3.,  4.,  7.,  8., 11., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([a,b,c],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.concat([a,b,c],axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy=\n",
       "array([[[ 1.,  2.],\n",
       "        [ 3.,  4.]],\n",
       "\n",
       "       [[ 5.,  6.],\n",
       "        [ 7.,  8.]],\n",
       "\n",
       "       [[ 9., 10.],\n",
       "        [11., 12.]]], dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([a,b,c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 2), dtype=float32, numpy=\n",
       "array([[[ 1.,  2.],\n",
       "        [ 5.,  6.],\n",
       "        [ 9., 10.]],\n",
       "\n",
       "       [[ 3.,  4.],\n",
       "        [ 7.,  8.],\n",
       "        [11., 12.]]], dtype=float32)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([a,b,c],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 3), dtype=float32, numpy=\n",
       "array([[[ 1.,  5.,  9.],\n",
       "        [ 2.,  6., 10.]],\n",
       "\n",
       "       [[ 3.,  7., 11.],\n",
       "        [ 4.,  8., 12.]]], dtype=float32)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.stack([a,b,c],axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.stack([a,b,c],axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 2), dtype=float32, numpy=\n",
       "array([[ 1.,  2.],\n",
       "       [ 3.,  4.],\n",
       "       [ 5.,  6.],\n",
       "       [ 7.,  8.],\n",
       "       [ 9., 10.],\n",
       "       [11., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1.0,2.0],[3.0,4.0]])\n",
    "b = tf.constant([[5.0,6.0],[7.0,8.0]])\n",
    "c = tf.constant([[9.0,10.0],[11.0,12.0]])\n",
    "\n",
    "c = tf.concat([a,b,c],axis = 0)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[1., 2.],\n",
       "        [3., 4.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[5., 6.],\n",
       "        [7., 8.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 9., 10.],\n",
       "        [11., 12.]], dtype=float32)>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.split(value,num_or_size_splits,axis)\n",
    "tf.split(c,3,axis = 0)  #指定分割份数，平均分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[1., 2.],\n",
       "        [3., 4.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[5., 6.],\n",
       "        [7., 8.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       " array([[ 9., 10.],\n",
       "        [11., 12.]], dtype=float32)>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.split(c,[2,2,2],axis = 0) #指定每份的记录数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
