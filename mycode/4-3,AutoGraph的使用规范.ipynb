{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-3,AutoGraph的使用规范"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有三种计算图的构建方式：静态计算图，动态计算图，以及Autograph。\n",
    "\n",
    "TensorFlow 2.0主要使用的是动态计算图和Autograph。\n",
    "\n",
    "动态计算图易于调试，编码效率较高，但执行效率偏低。\n",
    "\n",
    "静态计算图执行效率很高，但较难调试。\n",
    "\n",
    "而Autograph机制可以将动态图转换成静态计算图，兼收执行效率和编码效率之利。\n",
    "\n",
    "当然Autograph机制能够转换的代码并不是没有任何约束的，有一些编码规范需要遵循，否则可能会转换失败或者不符合预期。\n",
    "\n",
    "我们将着重介绍Autograph的编码规范和Autograph转换成静态图的原理。\n",
    "\n",
    "并介绍使用tf.Module来更好地构建Autograph。\n",
    "\n",
    "本篇我们介绍使用Autograph的编码规范。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一，AutoGraph编码规范总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1，被@tf.function修饰的函数应尽可能使用TensorFlow中的函数而不是Python中的其他函数。例如使用tf.print而不是print，使用tf.range而不是range，使用tf.constant(True)而不是True.\n",
    "\n",
    "* 2，避免在@tf.function修饰的函数内部定义tf.Variable. \n",
    "\n",
    "* 3，被@tf.function修饰的函数不可修改该函数外部的Python列表或字典等数据结构变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二，AutoGraph编码规范解析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1，被@tf.function修饰的函数应尽量使用TensorFlow中的函数而不是Python中的其他函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "@tf.function\n",
    "def np_random():\n",
    "    a = np.random.randn(3,3)\n",
    "    tf.print(a)\n",
    "    \n",
    "@tf.function\n",
    "def tf_random():\n",
    "    a = tf.random.normal((3,3))\n",
    "    tf.print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[ 0.29236729, -0.41746961,  0.47220812],\n",
      "       [-0.21184983,  0.42983184,  1.49331272],\n",
      "       [ 0.38915247, -1.35473529, -0.69771196]])\n",
      "array([[ 0.29236729, -0.41746961,  0.47220812],\n",
      "       [-0.21184983,  0.42983184,  1.49331272],\n",
      "       [ 0.38915247, -1.35473529, -0.69771196]])\n"
     ]
    }
   ],
   "source": [
    "#np_random每次执行都是一样的结果。\n",
    "np_random()\n",
    "np_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.777999163 -0.650503099 -2.9260273]\n",
      " [-0.72183615 -1.08333409 -1.45962143]\n",
      " [-0.129088238 -0.789253771 0.545754969]]\n",
      "[[0.791928351 -2.8246057 1.34542322]\n",
      " [-0.446928084 1.02990949 0.0940940306]\n",
      " [-0.725948334 -0.595660388 -1.48860991]]\n"
     ]
    }
   ],
   "source": [
    "#tf_random每次执行都会有重新生成随机数。\n",
    "tf_random()\n",
    "tf_random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2，避免在@tf.function修饰的函数内部定义tf.Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 避免在@tf.function修饰的函数内部定义tf.Variable.\n",
    "\n",
    "x = tf.Variable(1.0,dtype=tf.float32)\n",
    "@tf.function\n",
    "def outer_var():\n",
    "    x.assign_add(1.0)\n",
    "    tf.print(x)\n",
    "    return(x)\n",
    "\n",
    "outer_var() \n",
    "outer_var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def inner_var():\n",
    "    x = tf.Variable(1.0,dtype = tf.float32)\n",
    "    x.assign_add(1.0)\n",
    "    tf.print(x)\n",
    "    return(x)\n",
    "\n",
    "#执行将报错\n",
    "# inner_var()\n",
    "#inner_var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3,被@tf.function修饰的函数不可修改该函数外部的Python列表或字典等结构类型变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=5.0>, <tf.Tensor: shape=(), dtype=float32, numpy=6.0>]\n"
     ]
    }
   ],
   "source": [
    "tensor_list = []\n",
    "\n",
    "#@tf.function #加上这一行切换成Autograph结果将不符合预期！！！\n",
    "def append_tensor(x):\n",
    "    tensor_list.append(x)\n",
    "    return tensor_list\n",
    "\n",
    "append_tensor(tf.constant(5.0))\n",
    "append_tensor(tf.constant(6.0))\n",
    "print(tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'x:0' shape=() dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "tensor_list = []\n",
    "\n",
    "@tf.function #加上这一行切换成Autograph结果将不符合预期！！！\n",
    "def append_tensor(x):\n",
    "    tensor_list.append(x)\n",
    "    return tensor_list\n",
    "\n",
    "append_tensor(tf.constant(5.0))\n",
    "append_tensor(tf.constant(6.0))\n",
    "print(tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
